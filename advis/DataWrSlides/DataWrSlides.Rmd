---
title: "Data Wrangling (Made Easy) in R Workshop"
author: "T. J. McKinley ([t.mckinley@exeter.ac.uk](mailto:t.mckinley@exeter.ac.uk))"
fontsize: 12pt
output: 
    beamer_presentation:
        latex_engine: xelatex
header-includes:
    - \input{header.tex}
---

```{r, include = F}
library(knitr)
knitr::opts_chunk$set(cache = F, echo = T, fig.align = "center", fig.width = 5, fig.height = 5, resize.width = "0.9\\textwidth", resize.height = "0.9\\textwidth")
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
```

## Recap: 'Tidy' data

Specifically, a **tidy** data set is one in which:

* **rows** contain different **observations**;
* **columns** contain different **variables**;
* **cells** contain values.

Remember:

> "Tidy datasets are all alike but every messy dataset is messy in its own way."---[Hadley Wickham](http://hadley.nz/)

## The `tidyverse`

In the previous session we explored the use of `ggplot2` to produce visualisations of complex data sets.

This utilised the fact that the data sets we had available were **'tidy'** (in the Wickham sense)!

However, it is estimated that data scientists spend around [50-80% of their time cleaning and manipulating data](https://www.nytimes.com/2014/08/18/technology/for-big-data-scientists-hurdle-to-insights-is-janitor-work.html?_r=0).

In this session we will explore the use of other `tidyverse` packages, such as `dplyr` and `tidyr`, that facilitate effective **data wrangling**.

## Cheat sheets

As before, useful cheat sheets can be found at:
\bc

[https://www.rstudio.com/resources/cheatsheets/](https://www.rstudio.com/resources/cheatsheets/)

\ec
I would highly recommend downloading the appropriate ones (note that they do get updated from time-to-time as the packages are further developed).

## Further reading
\small
I would highly recommend Hadley Wickham and Garrett Grolemund's [**"R for Data Science"**](https://r4ds.had.co.nz/) book:

\begin{center}
\includegraphics[width = 0.2\textwidth]{images/RforDS.png}
\end{center}

Can be bought as a hard copy, or a link to a free HTML version is [here](https://r4ds.had.co.nz/).

## Structure of the workshop

Full (and more comprehensive notes) are provided at:

\bc

[https://exeter-data-analytics.github.io/AdVis/](https://exeter-data-analytics.github.io/AdVis/)

\ec

You are encouraged to go through these in more detail outside of the workshop.

Today we will discuss the main concepts, and work through some (although not all) of the examples in **Section 2** of the notes.

I would encourage you to work from the HTML here, but a PDF is available as a link in the HTML notes.

## RStudio server

CLES have kindly offered the use of their RStudio server in case anyone needs it:

\bc

[https://rstudio04.cles.ex.ac.uk](https://rstudio04.cles.ex.ac.uk)

\ec

**Please note that this server is only for use for this workshop, unless you otherwise have permission to use it .**

You will need to log-in using your University log-in details.

## What we're aiming for...

\centering
\includegraphics[width=0.8\textwidth]{images/poppyramid.pdf}

## Basic operations

We will assume here that we are working with `data.frame`^[or `tibble`---see later] objects^[note that the `purrr` package provides functionality to wrangle different types of object, such as standard `list`s. We won't cover these here, but see Hadley's book, or the tutorials on the [`tidyverse`](https://www.tidyverse.org/) website for more details]. Common data wrangling tasks include:

* sorting;
* **filtering**;
* **selecting** columns;
* transforming columns.

## Basic operations

These basic operators all have an associated function:

\bcols
\bcolt{0.48}

* sorting:
* **filtering**:
* **selecting** columns:
* transforming columns:

\ecol
\bcolt{0.48}

* `arrange()`;
* `filter()`;
* `select()`;
* `mutate()`.

\ecol
\ecols

However, each of these operations can be done in base R. So why bother to use these functions at all?

## Why bother?
\small
\gap[-1]

1. These functions are written in a **consistent** way: they all take a `data.frame`/`tibble` objects as their initial argument and return a revised `data.frame`/`tibble` object. 
2. Their names are informative. In fact they are **verbs**, corresponding to us **doing something specific** to our data. This makes the code much more readable, as we will see subsequently.
3. They do not require extraneous operators: such as `$` operators to extract columns, or quotations around column names.
4. Functions adhering to these criteria can be developed and expanded to perform all sorts of other operations, such as summarising data over groups.
5. They can be used in **pipes** (see later).

## Aside: `tibble`s

`tidyverse` introduces a new object known as a `tibble`. Paraphrased from the `tibble` webpage:

> A `tibble` is an opinionated `data.frame`; keeping the bits that are effective, and throwing out what is not. Tibbles are **lazy** and **surly**: they do less (i.e. they don’t change variable names or types, and don’t do partial matching) and complain more (e.g. when a variable does not exist). **This forces you to confront problems earlier, typically leading to cleaner, more expressive code.**^[`tibble`s also have an enhanced `print()` method].

## Aside: `tibble`s
\small
The `readr` package (part of `tidyverse`) introduces a `read_csv()`^[note the underscore (`read_csv`) **not** `read.csv()`] function to read .csv files in  as `tibble` objects e.g.

```{r, size = "scriptsize", eval = F}
gapminder <- read_csv("gapminder.csv")
gapminder
```

```{r, size = "tiny", echo = F, message = F, warning = F}
library(tidyverse)
gapminder <- read_csv("gapminder/gapminder.csv")
gapminder
```

## Aside: `tibble`s

**Notice**:

* `read_csv()` does not convert `characters` into `factors` automatically;
* the `print()` method includes information about the type of each variable (e.g. `integer`, `logical`, `character` etc.), as well as information on the number of rows and columns.

There is also an `as.tibble()` function that will convert standard `data.frame` objects into `tibble`s. 

In almost all of the `tidyverse` functions, you can use `data.frame` or `tibble` objects interchangeably.

## Example: Superheroes

These data have been extracted from some data scraped by [FiveThirtyEight](https://fivethirtyeight.com/), and available [here](https://github.com/fivethirtyeight/data/tree/master/comic-characters).

We will assume the complete data consist of three tables:

* `comics`: a table of characters and characteristics;
* `publisher`: a table of characters and who publishes them ([Marvel](https://www.marvel.com/) or [DC](https://www.dccomics.com/));
* `year_published`: characters against the year they were first published.

## Example: Superheroes

Let's have a look at the `comics` data frame:

```{r, echo = -1, message = F, warning = F, size = "scriptsize"}
comics <- readRDS("comics/comics.rds")
comics
```

## Example: Superheroes

To extract a subset of these data, we can use the `filter()` function e.g.

```{r, size = "scriptsize"}
filter(comics, HAIR == "Black Hair")
```

## Example: Superheroes

We can also filter by multiple variables and with negation e.g.

```{r, size = "scriptsize"}
filter(comics, HAIR == "Black Hair" & EYE != "Blue Eyes")
```

## Example: Superheroes

To sort these data, we can use the `arrange()` function e.g.

```{r, size = "scriptsize"}
arrange(comics, APPEARANCES)
```

## Example: Superheroes

We can prefix with a `-` sign to sort is descending order, and can sort by multiple variables e.g.

```{r, size = "scriptsize"}
arrange(comics, HAIR, -APPEARANCES)
```

## Example: Superheroes

To extract a subset of ***columns*** of these data, we can use the `select()` function e.g.

```{r, size = "scriptsize"}
select(comics, name, HAIR, APPEARANCES)
```

## Example: Superheroes

A `-` prefix *removes* a column e.g.

```{r, size = "scriptsize"}
select(comics, -APPEARANCES)
```

## Example: Superheroes

To *transform* or *add* columns, we can use the `mutate()` function^[see also `?transmute`] e.g.

```{r, size = "scriptsize"}
mutate(comics, logApp = log(APPEARANCES))
```

## Pipes

One of the most useful^[in my opinion] features of `tidyverse` is the ability to use **pipes**.

Piping comes from Unix scripting, and simply allows you to run a chain of commands, such that the results from each command feed into the next one. 

`tidyverse` does this using the `%>%` operator^[note that the fantastic [`magrittr`](https://cran.r-project.org/web/packages/magrittr/vignettes/magrittr.html) package does this more generally in R].

## Pipes
\small
The pipe operator in R works by passing the **result** of the *left-hand side* function into the **first** argument of the *right-hand side* function.

Since all the functions we've seen so far take a `data.frame` as their first argument, and return a `data.frame`, then we can chain these together e.g.

```{r, size = "scriptsize", eval = F}
comics %>%
    select(name, APPEARANCES) %>%
    arrange(-APPEARANCES) %>%
    mutate(logApp = log(APPEARANCES))
```

## Pipes
\small

\bcols
\bcol{0.58}

```{r, size = "scriptsize"}
comics %>%
    select(name, APPEARANCES) %>%
    arrange(-APPEARANCES) %>%
    mutate(logApp = log(APPEARANCES))
```

\ecol
\bcol{0.38}

**Notice**:

* No need for *temporary* variables;
* less verbose;
* can be read like prose (easier to understand)

\ecol
\ecols

**Note**: if splitting over multiple lines, the pipe operator must be at the end of the previous line.

## Your turn

Have a read through Sections 2.1 and 2.2 of the notes, and have a go at the tasks.

## Aside: `*_if` and `*_all`

There are some useful shortcut functions, notably: 

* `mutate_if()`;
* `mutate_all()`;
* `summarise_if()`;
* `summarise_all()`.

The `*_if()` functions apply a transformation or summary to a column **if** it adheres to some criteria. The `*_all()` functions apply the transformation or summary to **all** columns^[you will see the `summarise()` function shortly...].

## Aside: `*_if` and `*_all`

As a simple example, let's summarise the data:

```{r, size = "scriptsize", eval = F}
summary(comics)
```

```{r, size = "tiny", echo = F}
summary(comics)
```

Here the `character` columns do not provide a helpful summary. We could temporarily convert each `character` column to a `factor` to produce a better summary.

## Aside: `*_if` and `*_all`

Instead let's try:

```{r, size = "scriptsize", eval = F}
comics %>% 
    mutate_if(is.character, as.factor) %>%
    summary()
```

```{r, size = "tiny", echo = F}
comics %>% 
    mutate_if(is.character, as.factor) %>%
    summary()
```

This is much neater, and doesn't change the original data frame.

## Grouping and summarising
\small
We may also want to produce summaries for different **subsets** of the data. 

For example, let's say we want to produce a mean number of appearances for superheroes with different eye colours^[not very interesting I know...]. We do this using the `group_by()` and `summarise()` functions e.g.

\bcols
\bcol{0.48}

```{r, size = "scriptsize", results = 'hold', eval = F}
comics %>% 
    group_by(EYE) %>%
    summarise(
        meanApp = mean(APPEARANCES))
```

\ecol
\bcol{0.48}

```{r, size = "scriptsize", results = 'hold', echo = F}
comics %>% 
    group_by(EYE) %>%
    summarise(
        meanApp = mean(APPEARANCES)) %>%
    as.data.frame()
```

\ecol
\ecols

## Grouping and summarising
\small
A particularly useful function is `count()`, which tabulates the numbers of observations. This is particularly useful when combined with `group_by()` e.g.

\bcols
\bcol{0.48}

```{r, size = "scriptsize", results = 'hold', eval = F}
comics %>% 
    group_by(EYE) %>%
    count()
```

\ecol
\bcol{0.48}

```{r, size = "scriptsize", results = 'hold', echo = F}
comics %>% 
    group_by(EYE) %>%
    count() %>%
    as.data.frame()
```

\ecol
\ecols

## Your turn

Have a crack at Section 2.3 of the workshop.

## Gather and spread

Other really important functions are `gather()` and `spread()`.

These functions are used to **manipulate** `data.frame` objects into different forms.

They are often key to wrangling 'messy' data sets into 'tidy' data sets.

## Example: Senate predictions 2018

Let's look at an example from the [FiveThirtyEight](https://projects.fivethirtyeight.com/2018-midterm-election-forecast/senate/?ex_cid=rrpromo) website.

These data show the predicted probability of each party winning each seat, based on a statistical model fitted on 30th October 2018.

I have filtered and wrangled these data to illustrate these methods, the original data were in fact 'tidy'!

## Example: Senate predictions 2018

Let's have a look at the data.

\bcols
\bcol{0.58}

```{r, size = "scriptsize", echo = -c(1, 2)}
## load data
senate <- readRDS("senate/senate.rds")
head(senate)
```

\ecol
\bcol{0.38}

**Key**:

* **D**: Democrat
* **O**: Other
* **R**: Republican

\ecol
\ecols

These are **not** in 'tidy' format!

## Gather

To coerce these into 'tidy' format we can use the `gather()` function, which takes multiple columns, and gathers them into key-value pairs.

It takes the form:

```{r, eval = F}
gather(data, key, value, ...)
```

where  `...` is replaced with the names of the columns we wish to gather together (or the ones we wish to exclude from gathering).

This is best illustrated by an example.

## Example: Senate predictions 2018
\small

\bcols
\bcol{0.45}

```{r, size = "scriptsize", echo = F}
as.data.frame(senate[1, ])
```

\ecol
\bcol{0.55}

Here we want to collapse the columns labelled `D`, `O` and `R` into a new column called `party` (the **key**), with the predicted proportions in a column called `prop` (the **value**). We do not want `state` to be gathered.

\ecol
\ecols

```{r, size = "scriptsize", eval = F}
senate %>%
    gather(party, prop, -state)
```

```{r, size = "scriptsize", echo = F}
senate %>%
    gather(party, prop, -state) %>%
    as.data.frame() %>%
    head()
```

## Example: Senate predictions 2018
\gap[-1]
Note that the following are **equivalent**:

\bcols
\bcol{0.48}

```{r, size = "scriptsize", eval = F}
senate %>%
    gather(party, prop, -state)
```

\ecol
\bcol{0.48}

```{r, size = "scriptsize", eval = F}
senate %>%
    gather(party, prop, D, O, R)
```

\ecol
\ecols

You can chose whichever option is the most sensible.

You can also pipe together to remove the extraneous `NA`s (and overwrite the original `senate` object):

\bcols
\bcol{0.48}

```{r, size = "scriptsize", results = "hide"}
senate <- senate %>%
    gather(party, prop, -state) %>%
    filter(!is.na(prop))
```

\ecol
\bcol{0.48}

```{r, size = "scriptsize", echo = F}
senate %>%
    as.data.frame() %>%
    head()
```

\ecol
\ecols

## Spread
\small
`spread()` does the opposite of `gather()`: it takes two columns (`key` and `value`) and spreads these into multiple columns e.g.

\bcols
\bcol{0.48}

```{r, size = "scriptsize", eval = F}
senate
```

```{r, size = "scriptsize", echo = F}
senate %>%
    as.data.frame() %>% head()
```

\ecol
\bcol{0.48}

```{r, size = "scriptsize", eval = F}
senate %>%
    spread(party, prop)
```

```{r, size = "scriptsize", echo = F}
senate %>%
    spread(party, prop) %>%
    as.data.frame() %>%
    head()
```

\ecol
\ecols

## Example: Senate predictions 2018

We can now do some more complex analyses. For example, to produce a table of binary predictions based on $p > 0.5$ (using the 'tidy' version of the data):

```{r, size = "scriptsize", eval = F}
senate %>%
    mutate(outcome = ifelse(prop > 0.5, 1, 0)) %>%
    group_by(party, outcome) %>%
    count() %>%
    spread(party, n)
```  

```{r, size = "scriptsize", echo = F}
senate %>%
    mutate(outcome = ifelse(prop > 0.5, 1, 0)) %>%
    group_by(party, outcome) %>%
    count() %>%
    spread(party, n) %>%
    as.data.frame()
```

## Unite and separate

Other useful functions are `unite()` and `separate()`, the former takes multiple columns and binds them together, and the latter takes a single column and splits it apart. For example:

\bcols
\bcol{0.48}

```{r, size = "scriptsize", results = "hide"}
senate <- senate %>%
    mutate(outcome = 
      ifelse(prop > 0.5, 1, 0)) %>%
    group_by(party, outcome) %>%
    count()
senate
```

```{r, size = "scriptsize", echo = F}
senate %>%
    as.data.frame() %>%
    head()
```

\ecol
\bcol{0.48}

```{r, size = "scriptsize", results = "hide"}
senate <- senate %>%
    unite(outcome, 
          party, outcome, sep = "_")
senate
```

```{r, size = "scriptsize", echo = F}
senate %>%
    as.data.frame() %>%
    head()
```

\ecol
\ecols

## Unite and separate

To reverse this, we can use `separate()`:

\bcols
\bcol{0.38}

```{r, size = "scriptsize", results = "hide"}
senate
```

```{r, size = "scriptsize", echo = F}
senate %>%
    as.data.frame() %>%
    head()
```

\ecol
\bcol{0.58}

```{r, size = "scriptsize", results = "hide"}
senate <- senate %>%
    separate(outcome, 
      c("party", "outcome"), sep = "_")
senate
```

```{r, size = "scriptsize", echo = F}
senate %>%
    as.data.frame() %>%
    head()
```

\ecol
\ecols

## Your turn

Have a crack at Section 2.4 of the workshop.

## Joins
\small
A key data analytics skill is to be able to **join**  different tables together. This can be done using `*_join()` functions. Key types of join are:

* `inner_join()`
* `left_join()` / `right_join()`
* `full_join()`
* `semi_join()` / `anti_join()`

You can join tables by **cross-referencing** against **key variables**. As an example, let's join two tables relating to information on superheroes...

## Joins

```{r, size = "scriptsize"}
comics
```

\bcols 
\bcol{0.48}

```{r, size = "scriptsize", eval = F}
year_published
```

```{r, size = "scriptsize", echo = F}
year_published <- readRDS("comics/year_published.rds")
year_published
```

\ecol
\bcol{0.48}

Here we will join the two tables by **`name`**.

\ecol
\ecols

## `inner_join()`

The simplest type of join is an **inner join**. This joins two data frames and *retains only those rows in each data frame that can be matched* e.g.

```{r, size = "scriptsize"}
inner_join(comics, year_published, by = "name")
```

## `left_join()`

A **left join** retains *all rows* in the **left** data frame, but *only* rows in the **right** data frame that *can be matched* e.g.

```{r, size = "scriptsize"}
left_join(comics, year_published, by = "name")
```

Here R replaces elements it can't match with `NA`.

## `right_join()`

A **right join** retains *all rows* in the **right** data frame, but *only* rows in the **left** data frame that *can be matched* e.g.

```{r, size = "scriptsize"}
right_join(comics, year_published, by = "name")
```

This is the same as the `inner_join()` in this case. Why?

## `full_join()`

A **full join** retains *all rows* in the **both** data frames e.g.

```{r, size = "scriptsize"}
full_join(comics, year_published, by = "name")
```

This is the same as the `left_join()` in this case. Why?

## `semi_join()`

A **semi join** return *all rows* from the **left** data frame where there *are matching* values in the **right** data frame. It returns just columns in the **left** data frame, and does not duplicate rows (i.e. it is a *filtering* join):

```{r, size = "scriptsize"}
semi_join(comics, year_published, by = "name")
```

## `anti_join()`

An **anti join** return *all rows* from the **left** data frame where there *are* ***not*** *matching* values in the **right** data frame. It returns just columns in the **left** data frame, and does not duplicate rows (i.e. it is a *filtering* join):

```{r, size = "scriptsize"}
anti_join(comics, year_published, by = "name")
```

## Joins
\small
\gap[-1.5]
We can also join multiple tables together using e.g. **pipes** (or similar)

```{r, size = "scriptsize"}
comics
```
\gap[-1.4]
\bcols 
\bcolt{0.48}

```{r, size = "scriptsize", eval = F}
year_published
```

```{r, size = "scriptsize", echo = F}
year_published
```

\ecol
\bcolt{0.48}

```{r, size = "scriptsize", eval = F}
publisher
```

```{r, size = "scriptsize", echo = F}
publisher <- readRDS("comics/publisher.rds")
publisher
```

\ecol
\ecols

## Joins

```{r, size = "scriptsize"}
comics %>%
    full_join(year_published, by = "name") %>%
    full_join(publisher, by = "name")
```

## Joins

**Note**: you can also join by more than one variable e.g.

```{r, eval = F, size = "scriptsize"}
inner_join(x, y, by = c("variable1", "variable2"))
```

## Your turn

Have a crack at Section 2.5 of the workshop.

## Epilogue

You should now be ready to work through the final (more comprehensive) example in Section 2.6 of the workshop notes.

This brings together various aspects of the last two-days. We take multiple 'messy' data sets, join them together, wrangle them into the correct format and then plot them using `ggplot2`.

Along the way we use a few features of `tidyverse` that we haven't introduced, so I wouldn't expect you to be able to recreate this plot from scratch, but I want you to go through the code and understand what is happening.

## Epilogue

Hopefully these workshops have given you a flavour of the power of `tidyverse`.

I for one do most of my data analyses using `tidyverse` now, although remember that it may not be suitable for all types of data / analysis method, so you should view it as one tool in your data science arsenal.

If this has whetted your appetite, I can thoroughly recommend Hadley Wickham and Garrett Grolemund's [**"R for Data Science"**](https://r4ds.had.co.nz/) book!

Please feel free to e-mail me if you have any further questions.


