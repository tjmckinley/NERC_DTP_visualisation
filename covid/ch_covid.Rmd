# (PART) Consolidation: COVID-19 in England and Wales  {-}

# COVID-19 mortality risk by age and sex {#spiegelhalter}

Now that you are familiar with R and some key `tidyverse` packages, let's use some of these skills to explore and visualise some real-world data on COVID-19 risk in the UK.

```{info, title = "Note", collapsible = FALSE}
A PDF handout for the slides for this part of the module can be found on the ELE page`r ifelse(!is_latex_output(), " or via the link [here](covid/uploadFiles/covidHANDOUT.pdf)", "")`. A PDF version of the slides (not in handout form) and a HTML version (which should be compatible with screen-readers) can also be found on ELE`r ifelse(!is_latex_output(), ", or via the links [here](covid/uploadFiles/covidSLIDES.pdf) and [here](covid/uploadFiles/covidSLIDES.html)", "")`.

All required data files can be downloaded from ELE`r ifelse(!is_latex_output(), " or [here](covid/uploadFiles/datasets_covid.zip)", "")`.
```

In an influential early paper on COVID-19 mortality risk, [Professor David Spiegelhalter](http://www.statslab.cam.ac.uk/~david/) compared COVID-19 mortality rates to the "normal" risk of dying from other causes, in order to find a suitable analogue to aid understanding about the risk of mortality following COVID-19 infection. 

> *'As covid-19 turns from a societal threat into a matter of risk management, it is vital that the associated risks are understood and clearly communicated. But these risks vary hugely between people, and so finding appropriate analogues is a challenge. Although covid-19 is a complex multisystem disease that can cause prolonged illness, here I focus solely on the risks of dying from covid-19 and explore the use of "normal" risk---the risk of death from all causes each year---as an aid to transparent communication.'*---David Spiegelhalter

[Spiegelhalter D. Use of "normal" risk to improve understanding of dangers of covid-19, *BMJ*, 2020; 370 :m3259](https://www.bmj.com/content/370/bmj.m3259).

Interestingly, this paper used little statistical modelling. Rather, it used publicly available data and insightful visualisation and summarisation to make its main points. Here we will focus on reproducing Figure 1 and Table 2 from this paper. For ease, these are replicated in Figures \@ref(fig:spiegelhalter) and \@ref(fig:table2).

(ref:spiegelhalter) From [Spiegelhalter (2020)](https://www.bmj.com/content/370/bmj.m3259). Original figure legend: *Observed population fatality rates for 49 607 deaths mentioning covid-19, registered in England and Wales between 7 March and 26 June 2020. The covid-19 death rates create a remarkably straight line on a logarithmic scale (top), indicating an exponential increase of risk with age. The "normal" risk (dashed lines) is the actuarial annual mortality, scaled by a factor 16/52 to reflect the risk over 16 weeks.*

```{r, spiegelhalter, fig.cap = "(ref:spiegelhalter)", echo = FALSE, out.width = '40%'}
include_graphics("covid/images/F1.large.jpg")
```

Here the actuarial ("normal") risk of dying is defined as the probability that an individual of a given age/sex will not survive to their next birthday, and Figure \@ref(fig:spiegelhalter) shows a scaled version of this measure. If you first look at the actuarial risk of dying, you can see that there is an early peak, which is related to congenital diseases and birth trauma. The risk of dying then decreases during childhood, followed by a steady increase from ages 9--10 onwards. There is an elevated risk in the late teens and early 20s which is caused by additional deaths from non-natural causes. You can also see that on average males have a higher risk of dying than females across all age-classes. A **linear** line on the **log-scale** with respect to age, relates to an **exponential** curve on the original risk scale, which is shown on the bottom plot of Figure \@ref(fig:spiegelhalter).

The analogous COVID-19 mortality risk with age is also shown. Here you can see that the relationship with age is linear once again on the log-scale, and the gradient on the line is slightly larger than for the actuarial risk, although for ages over 45 the lines are roughly parallel, meaning that the risk of dying from COVID-19 is roughly proportional to the normal risk.

## Re-creating Figure 1 from Spiegelhalter (2020)

To reproduce this figure, we will need:

* to find and import life-tables for normal mortality risk by age and sex;
* find population sizes and COVID-19 death counts by age and sex;
* create mortality risk estimates for COVID-19 and place both risk estimates on the same scale;
* join these together and produce a plot of mortality risk by age, sex and type.

### National life tables for England and Wales

[Life tables](https://en.wikipedia.org/wiki/Life_table) show the probability of death within the next year, for individuals who survive to different ages. They are derived (typically) from mortality data and in the UK these data are collated by the [Office for National Statistics](https://www.ons.gov.uk/).

The most recent life tables for England and Wales (at the time of writing), can be found here:

[https://www.ons.gov.uk/peoplepopulationandcommunity/birthsdeathsandmarriages/lifeexpectancies/datasets/nationallifetablesenglandreferencetables](https://www.ons.gov.uk/peoplepopulationandcommunity/birthsdeathsandmarriages/lifeexpectancies/datasets/nationallifetablesenglandreferencetables)

For ease, the version of the data used in the analysis below is found in the  `r ifelse(!is_latex_output(), "[nationallifetables3yearew.xlsx](covid/uploadFiles/nationallifetables3yearew.xlsx)", "*nationallifetables3yearew.xlsx*")` file.

You will notice that this is an Excel file, not a `.csv` file. To make compatible with the analysis in Spiegelhalter (2020), we will extract the life tables for the time period 2016--2018, which can be found in the corresponding worksheet as shown in Figure \@ref(fig:lifetables). 

```{r, lifetables, fig.cap = "Life Tables", echo = FALSE, out.width = '60%'}
include_graphics("covid/images/covidExcel.png")
```

From the `Notation` tab in the Excel file we can extract the necessary details about the data set:

* $m_x$: is the central rate of mortality, defined as the number of deaths at age $x$ last birthday in the three year period to which the National Life Table relates divided by the average population at that age over the same period.
* $q_x$: is the mortality rate between age $x$ and $(x + 1)$, that is the probability that a person aged $x$ exact will die before reaching age $(x + 1)$.
* $l_x$: is the number of survivors to exact age $x$ of 100,000 live births of the same sex who are assumed to be subject throughout their lives to the mortality rates experienced in the three year period to which the National Life Table relates.
* $d_x$: is the number dying between exact age $x$ and $(x + 1)$ described similarly to $l_x$, that is $d_x = l_x - l_{x + 1}$.
* $e_x$: is the average period expectation of life at exact age $x$, that is the average number of years that those aged $x$ exact will live thereafter based on the mortality rates experienced in the three year period to which the National Life Table relates.

```{task, title = "Question"}
Is this data set 'tidy'?
```

```{solution, title = "Answer"}
No, this data set is not tidy. You can see that these data have been stored in a table that is designed for visualisation (it is a great format for putting into a scientific report for example). However, it is not a convenient format for analysis: 

* the column headers don't start until row 6; 
* there are two rows of column headers;
* there are multiple columns corresponding to the same variable but for different subsets (e.g. columns B and H correspond to $m_x$ for males and females respectively);
* there are empty columns (column G).

Hence we have a bit of work to do to make this "tidy".
```

Once we have downloaded the file to the working directory, we have two main options for extracting the data into R:

1. We open the file in Excel, navigate to the correct tab (`2016-2018`), then save the worksheet as e.g. a `.csv` file via *File -> Save As...*. We then load into R using `read_csv()` as we have done previously.
2. We can use the `read_excel()` function from the `readxl` package to read directly from the `.xlsx` file. (Note that `readxl` is part of the `tidyverse`, though it is not loaded automatically, hence the additional `library` call below.) 

```{info, title = "Note", collapsible = FALSE}
The first option you can do yourselves. You might also want to tidy up the dataset a bit before loading it into R. This is often done, though it does means that the steps you've taken to do the clean-up are **not documented** (though this could be done separately). 

To expand your skill set a bit more, let's illustrate the second option, but also **without changing the original file** in any way, making the full data cleaning process entirely **reproducible**. 
```

Let's start by loading the libraries and reading in the correct worksheet from the `.xlsx` file:

```{r, message = FALSE}
## load libraries
library(tidyverse)
library(readxl)
```

```{r, eval = FALSE}
## read in the correct worksheet from the .xlsx
lifetables <- read_excel("nationallifetables3yearew.xlsx", sheet = "2016-2018")
lifetables
```

```{r, message = FALSE, warning = FALSE, echo = FALSE}
## read in the correct worksheet from the .xlsx
lifetables <- read_excel("covid/uploadFiles/nationallifetables3yearew.xlsx", sheet = "2016-2018")
lifetables
```

Notice here that there is a bunch of gumpf at the top of the file, which isn't required. There are various ways to deal with this, but since the tables are quite small here, I am going to use the `range` option to `read_excel()` to extract the data for males and females separately, and then bind the resulting `tibble` objects together. You could do this in a single piped workflow, but to break the problem up a bit here I've read males and females into separate objects and then bound them together afterwards. Notice that we need to also extract the `x` column separately for females, since it's not contiguous to the other columns.

```{r, eval = FALSE}
## read in males
males <- read_excel("nationallifetables3yearew.xlsx", 
        sheet = "2016-2018", range = "A7:F108") %>%
    mutate(sex = "male")

## read in females
females <- read_excel("nationallifetables3yearew.xlsx", 
        sheet = "2016-2018", range = "A7:A108") %>%
    cbind(
        read_excel("nationallifetables3yearew.xlsx", 
            sheet = "2016-2018", range = "H7:L108")
    ) %>%
    mutate(sex = "female")

## bind together and cleanup
lifetables <- rbind(males, females) %>%
    rename(age = x)
rm(males, females)
lifetables
```

```{r, message = FALSE, echo = FALSE}
## read in males
males <- read_excel("covid/uploadFiles/nationallifetables3yearew.xlsx", 
        sheet = "2016-2018", range = "A7:F108") %>%
    mutate(sex = "male")

## read in females
females <- read_excel("covid/uploadFiles/nationallifetables3yearew.xlsx", 
        sheet = "2016-2018", range = "A7:A108") %>%
    cbind(
        read_excel("covid/uploadFiles/nationallifetables3yearew.xlsx", 
            sheet = "2016-2018", range = "H7:L108")
    ) %>%
    mutate(sex = "female")

## bind together and cleanup
lifetables <- rbind(males, females) %>%
    rename(age = x)
rm(males, females)
lifetables
```

This is much better. Notice that all the columns have the expected headings and are of the expected format. If the code doesn't make sense, then try running each set of lines separately (remember, for nested functions, the internal functions are run first). (I've had to break some of the functions across lines in order to fit on the page, but you shouldn't have to.)

```{task, title = "Question"}
Is this data set 'tidy'?
```

```{solution, title = "Answer"}
Yes, this data set is now tidy. Each row corresponds to an individual observation, each column to a variable and each cell to a specific value. It was not tidy in the original Excel file. Note that we could have tackled this differently, perhaps by reading in the whole table and using `pivot_longer()`/`pivot_wider()` operations to massage into tidy format, but this approach seemed reasonable to me here. Feel free to have a play with other methods.
```

```{info, title = "Note", collapsible = FALSE}
For more information on the `readxl` package, see: [https://readxl.tidyverse.org/](https://readxl.tidyverse.org/).
```

The quantities that are plotted in Spiegelhalter (2020) Figure 1 are rescaled age- and sex-specific annual population fatality rates. Formally this is the probability that an individual dies before age `x + 1`, given that they have survived to age `x`.

```{task}
Identify the column in the data corresponding to the age- and sex-specific annual population fatality rates. Produce a plot of these population fatality rates against age, stratified by sex.
```

```{solution}
The correct column is `qx`, hence a suitable plot would be:
    
``{r}
ggplot(lifetables) +
    geom_point(aes(x = age, y = qx, colour = sex)) +
    xlab("Age (years)") + ylab("Annual population fatality rate")
``

```

```{task}
Figure \@ref(fig:spiegelhalter) rescales these rates to be in deaths per 100,000 people. The paper also scales this new measure by 16/52 to represent the hazard rate over 16 weeks instead of annually. (This latter part is to make consistent with the 16-week period of the COVID-19 death data that was used in the analysis.) Update the `qx` column in the data to correspond to this new scaled risk. Produce a new plot of the population fatality risks against age, stratified by sex, but this time scaled to deaths per 100,000 people over a 16 week period.
```

```{solution}

``{r}
## update data
lifetables <- mutate(lifetables, qx = qx * 100000 * 16 / 52)

## plot of 16 week risk against age and sex
ggplot(lifetables) +
    geom_point(aes(x = age, y = qx, colour = sex)) +
    xlab("Age (years)") + ylab("Deaths per 100,000 people") +
    ggtitle("Population fatality rates over a 16-week period")
``

```

In the paper two plots are produced, one on the original scale and one on the log-scale.

```{task}
Reproduce the plot above, but for the log-mortality rate. Try to keep the axis labels in the same format as Figure \@ref(fig:spiegelhalter). [**Hint**: set an appropriate `scales_y_continuous` argument, rather than log-transforming the mortality rate directly. Take a look at the help file `?scales_y_continuous` if you're stuck, paying attention to the `trans` and `breaks` arguments.]
```

```{solution}

``{r}
ggplot(lifetables) +
    geom_point(aes(x = age, y = qx, colour = sex)) +
    xlab("Age (years)") + ylab("Deaths per 100,000 people") +
    ggtitle("Log-population fatality risks over a 16-week period") +
    scale_y_continuous(trans = "log", breaks = c(0.05, 0.2, 1, 5, 20, 100, 500, 2000))
``

```

### COVID-19 deaths in England and Wales

Now we extract the COVID-19 death data that was used in Spiegelhalter (2020). These data are available at:

[https://www.ons.gov.uk/peoplepopulationandcommunity/birthsdeathsandmarriages/deaths/datasets/weeklyprovisionalfiguresondeathsregisteredinenglandandwales](https://www.ons.gov.uk/peoplepopulationandcommunity/birthsdeathsandmarriages/deaths/datasets/weeklyprovisionalfiguresondeathsregisteredinenglandandwales)

For ease, the version of the data used in the analysis below can be found in the `r ifelse(!is_latex_output(), "[publishedweek262020.xlsx](covid/uploadFiles/publishedweek262020.xlsx)", "*publishedweek262020.xlsx*")` file.

You will notice that again this is an Excel file, not a `.csv` file. To make compatible with the analysis in Spiegelhalter (2020), we need death counts for England and Wales, stratified by age and sex. From the `Contents` worksheet we can see that these data can be found in the `Covid-19 - Weekly registrations` worksheet as shown in Figure \@ref(fig:coviddeaths). 

```{r, coviddeaths, fig.cap = "COVID deaths", echo = FALSE, out.width = '70%'}
include_graphics("covid/images/covidDeaths.png")
```

```{task, title = "Question"}
Is this data set 'tidy'?
```

```{solution, title = "Answer"}
No, this data set is not tidy. As before, this is a convenient format for visualisation, but more work is required to extract what we need for analysis. The key parts we need are:
    
* column headers on row 6;
* data for males in cells B33:AB53;
* data for females in cells B55:AB75.

Hence we have a bit of work to do to make this "tidy".
```

To tackle this we will extract males and females as before, and bind together, but we also need to extract the column names separately. Hence we will do this in a series of stages.  Although we only need the time period 7 March 2020--26th June 2020, we will extract all the dates here and subset later. Let's start by reading the data in for males and females and binding together as before.

```{r, eval = FALSE}
## read in the correct worksheet from the .xlsx
deaths <- read_excel("publishedweek262020.xlsx", 
        sheet = "Covid-19 - Weekly registrations", range = "B33:AB53") %>%
    mutate(sex = "male") %>%
    rbind(
        read_excel("publishedweek262020.xlsx", 
            sheet = "Covid-19 - Weekly registrations", range = "B55:AB75") %>%
        mutate(sex = "female")
    )
deaths
```

```{r, message = FALSE, echo = FALSE}
## read in the correct worksheet from the .xlsx
deaths <- read_excel("covid/uploadFiles/publishedweek262020.xlsx", 
        sheet = "Covid-19 - Weekly registrations", range = "B33:AB53") %>%
    mutate(sex = "male") %>%
    rbind(
        read_excel("covid/uploadFiles/publishedweek262020.xlsx", 
            sheet = "Covid-19 - Weekly registrations", range = "B55:AB75") %>%
        mutate(sex = "female")
    )
deaths
```

Notice that the first column relates to the age categories, and has been read in as a `character` column (although the column name is incorrect due to the way the data were stored---we will correct this shortly). The other columns are the death counts, and have been read in as `numeric` values, as expected. The column names are all nonsensical, due to the formatting of the original file, so let's sort those out now. Let's read in the row of dates (cells C6:AB6) from the Excel file, which should return an empty `tibble` object with column names corresponding to the cells read in[^cells]. We then pipe this to the `colnames()` function, which should return a vector of column names:

[^cells]: since `col_names = TRUE` by default in the `read_excel()` function

```{r, eval = FALSE}
## create vector of column names
dates <- read_excel("publishedweek262020.xlsx", 
        sheet = "Covid-19 - Weekly registrations", range = "C6:AB6") %>%
    colnames()
dates
```

```{r, message = FALSE, echo = FALSE}
## create vector of column names
dates <- read_excel("covid/uploadFiles/publishedweek262020.xlsx", 
        sheet = "Covid-19 - Weekly registrations", range = "C6:AB6") %>%
    colnames()
dates
```

Woah, what has happened here? These are numbers not dates! Well, this is because Excel stores dates and times as numbers under the hood; else you could not perform operations such as calculating the number of days between two dates. Hence, what is displayed on the screen in Excel is not always equivalent to how the object is stored internally. If you examine the cell format for these cells, you will see that they are stored as dates and not text. Hence when R reads these in and converts into `character` types (since column names must be `character` types), it converts the underlying `numeric` representation into a `character`. Fortunately, Excel always stores dates as the number of days after 30th December 1899, and as such we can use a useful function called `as.Date()` in R to convert back into a date object (with the `origin` argument set appropriately---note the specific format).

```{r}
## convert into date object
dates <- as.numeric(dates) %>%
    as.Date(origin = "1899-12-30")
dates
class(dates)
```

This looks better. Although when we print the `dates` object to the screen it looks like a `character`, if we check the `class` we can see that it is stored as a `Date` object. Similarly to Excel, `Date` objects are special classes in R that display to the screen as if they are `character` types, but can be manipulated numerically (but in a clever way; for example, taking a difference between two dates will return the number of days in between them, but accounting for leap-years etc.).

```{info, title = "Note", collapsible = FALSE}
There are lots of useful things you can do with date objects. Although we are not using it here, the `lubridate` package, which is part of the `tidyverse` has lots of really useful features. If you're interested, check out the webpage (and associated cheat sheet) [here](https://lubridate.tidyverse.org/).
```

Of course, now that we have gone to all this effort, we must now convert back to a `character` type in order to use these as column names for the `deaths` data set. Note also that the first column of `deaths` corresponds to `age` and the final one to `sex`, and hence we will  create a vector of column names, and then set `colnames(deaths)` equal to this vector:

```{r, deaths, eval = FALSE}
## set the column names
colnames(deaths) <- c("age", as.character(dates), "sex")
deaths
```

\newpage

```{r, ref.label = "deaths", echo = FALSE}
```

```{task}
Why is this data frame still not 'tidy'? Convert to 'tidy' format and convert the date column back into a `Date` object. [**Hint**: use `pivot_longer()` to tidy up. To convert a `character` column to a `Date` object, use `as.Date()`[^date].]
```

```{solution}
It is still not tidy because the deaths are spread across multiple columns, with each column corresponding to a specific date and each row corresponding to a specific age/sex combination. For this to be tidy we need to create a data set with columns for deaths, age, sex and date. We can do this easily using `pivot_longer()`, followed by a `mutate()` call to convert the `date` characters into `Date` types.

``{r}
## make tidy
deaths <- pivot_longer(deaths, !c(age, sex), names_to = "date", values_to = "deaths") %>%
    mutate(date = as.Date(date))
``

```

[^date]: here the dates are in the format `"%Y-%m-%d"`, where `%Y` corresponds to four-digit year, `%m` to month and `%d` to day. This is the default and so no further arguments to `as.Date` are required (see the help file `?as.Date`). If the format were different, say if they were in US date format (e.g. "03/31/2020"), then you would need to set the format explicitly using the `format` argument, making sure the format argument matched the input character e.g. `as.Date("03/31/2020", format = "%m/%d/%Y)`. 

Your final data set should look something like this:

```{r}
deaths
```

### Population sizes

Now we extract the population size data that was used in Spiegelhalter (2020). These data are available at:

[https://www.ons.gov.uk/peoplepopulationandcommunity/populationandmigration/populationestimates/datasets/populationestimatesforukenglandandwalesscotlandandnorthernireland](https://www.ons.gov.uk/peoplepopulationandcommunity/populationandmigration/populationestimates/datasets/populationestimatesforukenglandandwalesscotlandandnorthernireland)

For ease, the version of the data used in the analysis below is in the `r ifelse(!is_latex_output(), "[ukmidyearestimates20182019ladcodes.xls](covid/uploadFiles/ukmidyearestimates20182019ladcodes.xls)", "*ukmidyearestimates20182019ladcodes.xls*")` file.

To make compatible with the analysis in Spiegelhalter (2020), we will use the mid-year population counts for 2018. From the `Contents` worksheet we can see that we need to extract data from the `MYE2 - Males` and `MYE2 - Females` worksheets as shown in Figure \@ref(fig:population). 

```{r, population, fig.cap = "Population estimates", echo = FALSE, out.width = '70%'}
include_graphics("covid/images/populationSizes.png")
```

```{task, title = "Question"}
Is this data set 'tidy'?
```

```{solution, title = "Answer"}
Nope. Again we can see that the `age` variable is split across multiple columns and the `sex` information is split across multiple worksheets.
```

```{task}
The data for males and females are contained in cells `A5:CQ435` in worksheets `MYE2 - Males` and `MYE2 - Females` respectively. Create two `tibble` objects called `pop_males` and `pop_females` respectively that contain the relevant data.
```

```{solution}

``{r, eval = FALSE}
## read in the correct worksheet from the .xlsx
pop_males <- read_excel("ukmidyearestimates20182019ladcodes.xls", 
        sheet = "MYE2 - Males", range = "A5:CQ435")
pop_females <- read_excel("ukmidyearestimates20182019ladcodes.xls", 
        sheet = "MYE2 - Females", range = "A5:CQ435")
``

```

```{task}
Add an appropriate `sex` column to each data set above, and bind them together into one data set called `pop`. Note that due to the footnote in cell `C5` of the `MYE2 - Males` worksheet (see Figure \@ref(fig:population)), you will also have to rename this column in the `males` data frame before you bind to `females`, else it will return an error because the names don't match.
```

```{solution}

``{r, eval = FALSE}
## add sex column
pop_males <- mutate(pop_males, sex = "male") %>%
    rename(Geography = Geography1)
pop_females <- mutate(pop_females, sex = "female")

## bind together
pop <- rbind(pop_males, pop_females)
``

```

```{task}
Convert `pop` into tidy format. Remove the `All ages` column and then pivot the remaining appropriate columns into new `age` and `population` columns. Make sure both new columns are `numeric`.
```

```{solution}

``{r, eval = FALSE}
## convert to tidy format
pop <- select(pop, !`All ages`) %>%
    pivot_longer(!c(Code, Name, Geography, sex), names_to = "age", values_to = "population") %>%
    mutate(age = as.numeric(age))
``

```

```{r, message = FALSE, echo = FALSE}
## read in the correct worksheet from the .xlsx
pop_males <- read_excel("covid/uploadFiles/ukmidyearestimates20182019ladcodes.xls", 
        sheet = "MYE2 - Males", range = "A5:CQ435")
pop_females <- read_excel("covid/uploadFiles/ukmidyearestimates20182019ladcodes.xls", 
        sheet = "MYE2 - Females", range = "A5:CQ435")

## add sex column
pop_males <- mutate(pop_males, sex = "male") %>%
    rename(Geography = Geography1)
pop_females <- mutate(pop_females, sex = "female")

## bind together
pop <- rbind(pop_males, pop_females)

## convert to tidy format
pop <- select(pop, !`All ages`) %>%
    pivot_longer(!c(Code, Name, Geography, sex), names_to = "age", values_to = "population") %>%
    mutate(age = as.numeric(age))
```

Excellent work. Your tidied data set should now look something like:

```{r}
pop
```

### Creating population fatality risks for COVID-19 infection

Now that we have done most of the hard work, we can merge the information from the `deaths` and `pop` data sets to create **population fatality rates** for COVID-19. Remember, these can be estimated as the *number of deaths from COVID-19* divided by the *population size* in each age/sex cohort. We have read in much more information than we need to match the calculation in Spiegelhalter (2020), so we will proceed through a series of steps to extract the correct data from the different data sets, and then bind them together to create the required population fatality risks.

```{task}
Extract all data from the `deaths` data set for the time period between 7 March and 26 June 2020 (inclusive). Aggregate the deaths counts together across the whole time period for each `age`/`sex` combination. Save this as a new object called `deaths_sub`.
```

```{solution}

``{r, eval = FALSE}
## extract relevant data
deaths_sub <- filter(deaths, date >= as.Date("2020-03-07") & date <= as.Date("2020-06-26")) %>%
    group_by(age, sex) %>%
    summarise(deaths = sum(deaths), .groups = "drop")
``

```

```{r, echo = FALSE}
## extract relevant data
deaths_sub <- filter(deaths, date >= as.Date("2020-03-07") & date <= as.Date("2020-06-26")) %>%
    group_by(age, sex) %>%
    summarise(deaths = sum(deaths), .groups = "drop")
```

This new object should look something like:

```{r, deaths_sub, eval = FALSE}
deaths_sub
```

\newpage

```{r, ref.label = "deaths_sub", echo = FALSE}
```

```{task}
Extract the population sizes for England and Wales for each `age`/`sex` combination from the `pop` data frame and save as a new `pop_sub` object. Drop all columns except `age`, `sex` and `population`.
```

```{solution}

``{r, eval = FALSE}
## extract relevant data
pop_sub <- filter(pop, Name == "ENGLAND AND WALES") %>%
    select(!c(Name, Geography, Code))
``

```

```{r, echo = FALSE}
## extract relevant data
pop_sub <- filter(pop, Name == "ENGLAND AND WALES") %>%
    select(!c(Name, Geography, Code))
```

This new object should look something like:

```{r}
pop_sub
```

Notice that in `pop_sub` the `age` column is `numeric`, whereas in `deaths_sub` it is grouped. Examining the groups we can see that:

```{r}
unique(deaths_sub$age)
```

To join the populations table to the deaths table, we will need to group the `age` column in `pop_sub` to match the groups above and then aggregate together the population sizes appropriately by age group. To do this we will use a useful function called `cut()` that can be used to split `numeric` vectors into groups (see `?cut` for more details):

```{r}
## create break points and labels for the cut function
age_breaks <- seq(4, 89, by = 5)
age_labels <- paste0(c(1, age_breaks[-length(age_breaks)] + 1), "-", age_breaks)

age_breaks <- c(-1, 0, age_breaks, max(pop_sub$age) + 1)
age_labels <- c("<1", age_labels, "90+")
```

```{r}
## create grouped data
pop_sub <- mutate(pop_sub, age_grp = cut(age, age_breaks, age_labels)) %>%
    group_by(age_grp, sex) %>%
    summarise(population = sum(population), .groups = "drop") %>%
    rename(age = age_grp)
```

This new object should look something like:

```{r}
pop_sub
```

Now the `deaths_sub` and `pop_sub` data sets are in the same format, and can thus be joined. Note that here we want to **join** these tables according to `age` and `sex`, rather than just bind one on top of the other like we did earlier. We can then calculate the population fatality risk and rescale to be in deaths per 100,000 population as before. Hence:

```{r, PFR, eval = FALSE}
## join tables together and calculate population fatality rates
PFR <- inner_join(deaths_sub, pop_sub, by = c("age", "sex")) %>%
    mutate(PFR = deaths / population) %>%
    mutate(PFR = PFR * 100000)
PFR
```

\newpage

```{r, ref.label = "PFR", echo = FALSE}
```

Since `age` is now a `character` type, R will plot or summarise in [lexicographical](https://en.wikipedia.org/wiki/Lexicographic_order) ordering. This means that e.g. the `10-14` group comes ***before*** the `5-9` group (since `1` comes before `5`). One way to overcome this is to convert `age` to a `factor`, and explicitly set the `levels` of the factor to match the ordering that you want. We already have a vector of ordered levels that we created earlier (`age_labels`) that we can use for this e.g. `factor(pop_sub$age, levels = age_labels)`.

```{task}
Produce a plot of the log-population fatality rates from COVID-19 against age, stratified by sex. Use a temporary `mutate()` call to convert the `age` column into a `factor` with the correct levels and then pipe into `ggplot()`. See the solution for some neat little tricks to make the $x$-axis labels more readable, the $y$-axis labels match Figure \@ref(fig:spiegelhalter), and tidy up the legend heading.
```

```{solution}
    
``{r}
mutate(PFR, age = factor(age, levels = age_labels)) %>%
    ggplot() +
        geom_point(aes(x = age, y = PFR, colour = sex)) +
        scale_y_continuous(trans = "log", breaks = c(0.05, 0.2, 1, 5, 20, 100, 500, 2000), 
            labels = function(x) format(x, scientific = FALSE, drop0trailing = TRUE)) +
        xlab("Age (years)") + ylab("Deaths per 100,000 people") +
        ggtitle("log-Population Fatality Rates") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
        labs(colour = "Sex")
``

```

```{task}
Produce a plot of the log-population fatality rates from COVID-19 against age, stratified by sex and "normal" risk vs. "COVID-19" risk like e.g. Figure \@ref(fig:spiegelhalter). To do this create a new dataset, based on `lifetables`, that contains the mean mortality risks for the different age-groups in the `PFR` data. Then join this new table to the `PFR` data to create one data set with both types of mortality estimate in it. Then plot the mortality risks against age, and stratified by sex and estimate type (normal/COVID).
```

```{solution}
    
``{r, uber, eval = FALSE}
## create new data frame
PFR_combined <- mutate(lifetables, age_grp = cut(age, age_breaks, age_labels)) %>%
    group_by(age_grp, sex) %>%
    summarise(Normal = mean(qx), .groups = "drop") %>%
    rename(age = age_grp) %>%
    inner_join(
        select(PFR, age, sex, PFR),
        by = c("age", "sex")
    ) %>%
    rename(COVID = PFR) %>%
    pivot_longer(!c(age, sex), names_to = "estimate", values_to = "PFR")

## produce plot
mutate(PFR_combined, age = factor(age, levels = age_labels)) %>%
    ggplot() +
        geom_point(aes(x = age, y = PFR, colour = sex, shape = estimate)) +
        scale_y_continuous(trans = "log", breaks = c(0.05, 0.2, 1, 5, 20, 100, 500, 2000),
            labels = function(x) format(x, scientific = FALSE, drop0trailing = TRUE)) +
        xlab("Age (years)") + ylab("Deaths per 100,000 people") +
        ggtitle("log-Population Fatality Rates") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
        labs(colour = "Sex", shape = "Estimate")
``

```

\newpage

Hopefully you should have something like:

```{r, message = FALSE, warning = FALSE, echo = FALSE, ref.label = "uber"}
```

### Combining plots with `patchwork`

There are a whole bunch of other packages built around the `tidyverse`. One really useful one is `patchwork`. This allows for different `ggplot2` images to be combined together into a single graphic. This is incredibly useful, especially for publication. Combining with the `ggsave()` function makes it easy to develop publication-ready plots in specific formats for e.g. submission to scientific journals. This can be installed from CRAN in the usual way, and a series of detailed vignettes can be found at [https://patchwork.data-imaginist.com/](https://patchwork.data-imaginist.com/).

Here we will use `patchwork` to create a single graphic with both the log- and linear-scale plots of the population fatality rates.

```{info, title = "Note", collapsible = FALSE}
Whilst `facet_wrap()` and `facet_grid()` can be used within `ggplot()` calls to produce multi-figure plots, these functions rely on the $x$- and $y$-aesthetics being the same across the set of plots. Hence they are great for producing the same plot type across subsets of the data, but they won't work if you want to combine different types of plot together. 

This is where `patchwork` shines. One thing that we haven't considered much is that you can actually save `ggplot` plots as objects in R. Which means that you can create lots of plots and save them as objects, and then use `patchwork` to create a single uber-`ggplot` object that combines these different plots together. You can even combine legends etc. across multiple plots, and add annotations and lots more. 
```

Since the log- and linear-scaled population fatality rates are on different scales, it makes sense to create two plots and bind them together using `patchwork`. The code below creates a `p1` object containing the log-scale plot. (We truncate the $y$-axis at around 2,000 for consistency with Spiegelhalter (2020) using `coord_cartesian()`.)

```{r, message = FALSE, warning = FALSE}
## create log-scale plot
p1 <- mutate(PFR_combined, age = factor(age, levels = age_labels)) %>%
        ggplot() +
            geom_point(aes(x = age, y = PFR, colour = sex, shape = estimate)) +
            scale_y_continuous(trans = "log", breaks = c(0.05, 0.2, 1, 5, 20, 100, 500, 2000), 
                labels = function(x) format(x, scientific = FALSE, drop0trailing = TRUE)) +
            xlab("Age (years)") + ylab("Deaths per 100,000 people") +
            ggtitle("log-Population Fatality Rates") +
            theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
            labs(colour = "Sex", shape = "Estimate") +
            coord_cartesian(ylim = c(0.01, 2000))
```

Now that the `p1` object has been created, if you print to the screen then the plot will appear:

```{r, message = FALSE, warning = FALSE}
p1
```

\newpage

```{task}
Produce a plot of the population fatality rates from COVID-19 (on the linear scale) against age, stratified by sex and "normal" risk vs. "COVID-19" risk like e.g. Figure \@ref(fig:spiegelhalter). Save as an object called `p2`. (You should be able to do this simply by changing the `scale_y_continuous()` and `ggtitle()` components of `p1`.)
```

```{solution}
Note that I've passed a `function` to the `labels` argument of `scale_y_continuous()` in order to nicely format the axis labels.

``{r}
p2 <- p1 +
    scale_y_continuous(breaks = c(400, 800, 1200, 1600, 2000), 
        labels = function(x) format(x, scientific = FALSE, drop0trailing = TRUE)) +
    ggtitle("Population Fatality Rates")
``

```

Now load the `patchwork` package, and then simply add the two plots together to combine:

```{r, message = FALSE, warning = FALSE, fig.width = 8, fig.height = 5, out.width = "90%"}
## load patchwork
library(patchwork)

## combine plots
p <- p1 + p2
p
```

Pretty cool eh? If we want one plot on top of the other, we can use the `/` operator:

```{r, message = FALSE, warning = FALSE, fig.width = 5, fig.height = 8}
## combine plots
p <- p1 / p2
p
```

\newpage

One more feature I really like is the ability to collect identical legends together:

```{r, message = FALSE, warning = FALSE, fig.width = 5, fig.height = 8}
## combine plots
p <- p1 / p2 + plot_layout(guides = "collect")
p
```

If you want to save as a .pdf file for example, then you can use `ggsave()`, e.g.

```{r, eval = FALSE}
ggsave("PFR.pdf", p, width = 5, height = 8)
```

This guesses the file type from the suffix in the filename, and allows you to set other aspects such as the width and height, or resolution if you are using a raster-based plot such as .jpg or .png[^pdf].

[^pdf]: the .pdf file here is *vector-based*, and so does not lose quality as you zoom in

There are so many things you can do with these types of plot, so please have a play. As a final example, consider trying to make the plot even closer to Figure \@ref(fig:spiegelhalter) by using lines instead of points for normal risk, and changing the colours to match exactly. Note that the line plots are easier to get working if `age` is `numeric`, rather than a `factor`, so in the code below we extract the midpoint of each category as a point estimate (treating `90+` as being `90--100` here). Run each set of lines to understand what's happening at each stage (there are a few functions such as `separate()` and `across()` that you may be less familiar with, so please see the help files to help understand these functions). To use different aesthetics for different subsets of the data, we can set the `data` argument to each `geom_*` as required.

```{r, davidplot, eval = FALSE}
## generate temporary data set with age-classes 
## converted to midpoints
temp <- PFR_combined %>%
    mutate(age = ifelse(age == "<1", "0-1", age)) %>%
    mutate(age = ifelse(age == "90+", "90-100", age)) %>%
    separate(age, c("LB", "UB"), sep = "-") %>%
    mutate(across(c(LB, UB), as.numeric)) %>%
    mutate(age = (LB + UB) / 2) 

## plot on log-scale
p1 <- ggplot(temp, aes(x = age, y = PFR)) +
        geom_line(aes(colour = sex, linetype = sex), 
            data = filter(temp, estimate == "Normal")) +
        geom_line(aes(group = sex), data = filter(temp, estimate == "COVID")) +
        geom_point(aes(colour = sex), data = filter(temp, estimate == "COVID")) +
        scale_y_continuous(trans = "log", breaks = c(0.05, 0.2, 1, 5, 20, 100, 500, 2000), 
            labels = function(x) format(x, scientific = FALSE, drop0trailing = TRUE)) +
        scale_colour_manual(values = c("blue", "red")) +
        scale_linetype_manual(values = c("longdash", "dashed")) +
        xlab("Age (years)") + ylab("Deaths per 100,000 people") +
        ggtitle("Log scale") +
        theme_bw() +
        theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
        coord_cartesian(ylim = c(0.05, 2000)) +
        labs(colour = "COVID-19", linetype = "Normal") +
        guides(
            linetype = guide_legend(override.aes = list(colour = c("blue", "red"))),
            colour = guide_legend(override.aes = list(linetype = NA))
        )

## plot on linear scale by just changing scales
p2 <- p1 + 
    ggtitle("Linear scale") +
    scale_y_continuous(breaks = c(400, 800, 1200, 1600, 2000), 
        labels = function(x) format(x, scientific = FALSE, drop0trailing = TRUE))

## combine plots using patchwork
p <- p1 / p2 + plot_layout(guides = "collect")
p
```

\newpage

```{r, ref.label = "davidplot", message = FALSE, warning = FALSE, fig.height = 8, fig.width = 8, echo = FALSE, out.width = "90%"}
```

\newpage

## Re-creating Table 2 from Spiegelhalter (2020)

We can also reconstruct Table 2 from Spiegelhalter (2020), which is shown in Figure \@ref(fig:table2). This expresses the mortality risks in different ways.

```{r, table2, fig.cap = "Table 2 from Spiegelhalter (2020)", echo = FALSE, out.width = '80%'}
include_graphics("covid/images/Table2.png")
```

```{task}
Create a data frame that contains the population counts and numbers of deaths in each age-category, but aggregated over sex. This can be done using the `pop_sub` and `deaths_sub` data frames created earlier. Amend the age-categories to match to Figure \@ref(fig:table2). (Note that there is one *minor* difference between the numbers in this new table and the numbers in Figure \@ref(fig:table2)---can you spot it?)
```

```{solution}

``{r}
## join deaths with population sizes
table2 <- group_by(pop_sub, age) %>%
    summarise(population = sum(population), .groups = "drop")
table2 <- group_by(deaths_sub, age) %>%
    summarise(deaths = sum(deaths), .groups = "drop") %>%
    inner_join(table2, by = "age")

## change age groupings and amalgamate counts accordingly
table2 <- mutate(table2, age = ifelse(age == "<1" | age == "1-4", "0-4", age)) %>%
    mutate(age = ifelse(age == "5-9" | age == "10-14", "5-14", age)) %>%
    mutate(age = ifelse(age == "15-19" | age == "20-24", "15-24", age)) %>%
    mutate(age = ifelse(age == "25-29" | age == "30-34", "25-34", age)) %>%
    mutate(age = ifelse(age == "35-39" | age == "40-44", "35-44", age)) %>%
    mutate(age = ifelse(age == "45-49" | age == "50-54", "45-54", age)) %>%
    mutate(age = ifelse(age == "55-59" | age == "60-64", "55-64", age)) %>%
    mutate(age = ifelse(age == "65-69" | age == "70-74", "65-74", age)) %>%
    mutate(age = ifelse(age == "75-79" | age == "80-84", "75-84", age)) %>%
    group_by(age) %>%
    summarise(deaths = sum(deaths), population = sum(population), .groups = "drop")
table2
``

Notice that this table has one more death in the `65-74` category, and one less in the `75-84` category. I can't quite remedy this, but it will make almost negligible difference to the results.
```

```{info, title = "Mathematical detail (if you are interested)", collapsible = TRUE}
Here are some mathematical details for the population fatality risk estimates in Figure \@ref(fig:table2) in case you are interested. Firstly, the **population fatality risk** in age-category $a$, denoted $\mbox{PFR}_a$, is the number of people who have died from COVID-19 in age-category $a$ (column 2), divided by the number of individuals in age-category $a$ (column 3). Hence:
$$
    \mbox{PFR}_a = \frac{\mbox{number of deaths in age-category $a$}}{\mbox{number of individuals in age-category $a$}}.
$$
This corresponds to the **probability** that a **randomly-selected** person in age-category $a$ will have died of COVID-19 during the study period. Since it is a **probability**, it is constrained to lie in the range $[0, 1]$. To express this as a rate per 100,000 individuals, we can then just multiply $\mbox{PFR}_a$ by 100,000 (column 4), or to express as a percentage, we multiply by 100 (column 5).

To calculate the PFR in terms of "1 death per $x$" population, we simply divide the population size (column 3) by the number of deaths (column 2) to calculate $x$; this is given in column 6 in Figure \@ref(fig:table2). 

To calculate the COVID-19 death rate as a percentage of the 5-year average death rates, we first calculate the number of deaths from COVID-19 in age-category $a$ (column 2) and divide this by the 5-year average for the number of deaths in age-category $a$ (column 8), and then multiply by 100 to convert from a proportion to a percentage. This is stored in column 9 in Figure \@ref(fig:table2). To convert this to *days of equivalent risk*, we can multiply the COVID-19 death rate as a **proportion** of the 5-year average death rate, by the number of days "at-risk", which here is 112 days since the beginning of the study period. This is stored in column 10 in Figure \@ref(fig:table2).
```
    
```{task}
Now calculate the COVID-19 death rates per 100,000 population and add to your new data frame.
```

```{solution}

``{r}
## calculate COVID-19 death rate per 100,000 population
table2 <- mutate(table2, PFR = 100000 * deaths / population)
table2
``

```

```{task}
Now calculate the COVID-19 death rates in terms of percentage of population size within each age-category, and add to your new data frame.
```

```{solution}

``{r}
## calculate COVID-19 death rate in percentage of population size
table2 <- mutate(table2, percentage = 100 * deaths / population)
table2
``

```


```{task}
Now calculate the COVID-19 death rates in terms of 1 death per $x$-population form and add to your new data frame.
```

```{solution}

``{r}
## calculate COVID-19 death rate in 1 per x-population
table2 <- mutate(table2, PFR1 = population / deaths)
table2
``

```

The next part of the table involves total deaths from all causes, not just COVID-19. These can be found in cells `B21:AB41` of the `Weekly figures 2020` worksheet in the the `r ifelse(!is_latex_output(), "[publishedweek262020.xlsx](covid/uploadFiles/publishedweek262020.xlsx)", "*publishedweek262020.xlsx*")` file.

```{task}
Read the death data into R and wrangle into the correct format to join with your COVID-19 summary table above. The death counts in the new data include the COVID-19 deaths, and so you will have to amend these to create a new column echoing the "Number of non-COVID deaths" column in Figure \@ref(fig:table2).
```

```{solution}

``{r, message = FALSE, warning = FALSE, eval = FALSE}
## read in the correct worksheet from the .xlsx
nonCovidDeaths <- read_excel("publishedweek262020.xlsx", 
        sheet = "Weekly figures 2020", range = "B21:AB41")
``

``{r, message = FALSE, warning = FALSE, echo = FALSE}
## read in the correct worksheet from the .xlsx
nonCovidDeaths <- read_excel("covid/uploadFiles/publishedweek262020.xlsx", 
        sheet = "Weekly figures 2020", range = "B21:AB41")
``

``{r, message = FALSE, warning = FALSE}
## set the column names as before
colnames(nonCovidDeaths) <- c("age", as.character(dates))

## tidy data and wrangle into correct format
nonCovidDeaths <- pivot_longer(nonCovidDeaths, !age, names_to = "date", values_to = "deaths") %>%
    mutate(date = as.Date(date)) %>%
    filter(date >= as.Date("2020-03-07") & date <= as.Date("2020-06-26")) %>%
    mutate(age = ifelse(age == "<1" | age == "1-4", "0-4", age)) %>%
    mutate(age = ifelse(age == "5-9" | age == "10-14", "5-14", age)) %>%
    mutate(age = ifelse(age == "15-19" | age == "20-24", "15-24", age)) %>%
    mutate(age = ifelse(age == "25-29" | age == "30-34", "25-34", age)) %>%
    mutate(age = ifelse(age == "35-39" | age == "40-44", "35-44", age)) %>%
    mutate(age = ifelse(age == "45-49" | age == "50-54", "45-54", age)) %>%
    mutate(age = ifelse(age == "55-59" | age == "60-64", "55-64", age)) %>%
    mutate(age = ifelse(age == "65-69" | age == "70-74", "65-74", age)) %>%
    mutate(age = ifelse(age == "75-79" | age == "80-84", "75-84", age)) %>%
    group_by(age) %>%
    summarise(nonCovidDeaths = sum(deaths), .groups = "drop")

## join with table2 and remove COVID deaths
table2 <- inner_join(table2, nonCovidDeaths, by = "age") %>%
    mutate(nonCovidDeaths = nonCovidDeaths - deaths)
table2
``

```

The next part of the table involves the five-year weekly average death counts. These can be found in cells `A7:BA27` of the `Figures` worksheet in the the `r ifelse(!is_latex_output(), "[weeklydeaths2015to20195yearaveragegenderagebands.xlsx](covid/uploadFiles/weeklydeaths2015to20195yearaveragegenderagebands.xlsx)", "*weeklydeaths2015to20195yearaveragegenderagebands.xlsx*")` file. At the current time the source for this information is:

[https://www.ons.gov.uk/peoplepopulationandcommunity/birthsdeathsandmarriages/deaths/adhocs/11644fiveyearaverageweeklydeathsregisteredinenglandandwalesbygenderandagegroupings](https://www.ons.gov.uk/peoplepopulationandcommunity/birthsdeathsandmarriages/deaths/adhocs/11644fiveyearaverageweeklydeathsregisteredinenglandandwalesbygenderandagegroupings)

Firstly we will read in the data:

```{r, message = FALSE, warning = FALSE, eval = FALSE}
## read in the correct worksheet from the .xlsx
weekly <- read_excel("weeklydeaths2015to20195yearaveragegenderagebands.xlsx", 
        sheet = "Figures", range = "A7:BA27")
weekly
```

```{r, message = FALSE, warning = FALSE, echo = FALSE}
## read in the correct worksheet from the .xlsx
weekly <- read_excel("covid/uploadFiles/weeklydeaths2015to20195yearaveragegenderagebands.xlsx", 
        sheet = "Figures", range = "A7:BA27")
weekly
```

You can see that each column (except the first) is a week of the year. We will use the `week()` function in the `lubridate` package to extract "week" information easily from dates (this should be installed as part of `tidyverse`, but similarly to `readxl` is not automatically loaded---hence the additional `library()` call below). 

```{info, title = "Note", collapsible = FALSE}
For more information on the `lubridate` package, see: [https://lubridate.tidyverse.org/](https://lubridate.tidyverse.org/).
```

Note that we have to convert the beginning and end of the time period into `Date` objects before we can use the `week()` function. We remove week 10 to match to the 16 week period reported in the paper. Note also the really useful `%in%` operator, which returns a logical vector, with `TRUE` entries for elements of the left-hand side that match **any** element on the right-hand side. 

```{r, message = FALSE, warning = FALSE}
## load lubridate
library(lubridate)

## extract "weeks" in time period of interest
weeksOfInterest <- week(as.Date("2020-03-08", format = "%Y-%m-%d"))
weeksOfInterest <- weeksOfInterest:week(as.Date("2020-06-26", format = "%Y-%m-%d"))
weeksOfInterest <- weeksOfInterest[-1]
weeksOfInterest
```

\newpage

```{r}
## pivot data into longer format and remove unwanted weeks
colnames(weekly) <- c("age", as.character(1:(ncol(weekly) - 1)))
weekly <- pivot_longer(weekly, !age, names_to = "week", values_to = "deaths") %>%
    filter(week %in% weeksOfInterest) %>%
    mutate(age = ifelse(age == "<1" | age == "1-4", "0-4", age)) %>%
    mutate(age = ifelse(age == "5-9" | age == "10-14", "5-14", age)) %>%
    mutate(age = ifelse(age == "15-19" | age == "20-24", "15-24", age)) %>%
    mutate(age = ifelse(age == "25-29" | age == "30-34", "25-34", age)) %>%
    mutate(age = ifelse(age == "35-39" | age == "40-44", "35-44", age)) %>%
    mutate(age = ifelse(age == "45-49" | age == "50-54", "45-54", age)) %>%
    mutate(age = ifelse(age == "55-59" | age == "60-64", "55-64", age)) %>%
    mutate(age = ifelse(age == "65-69" | age == "70-74", "65-74", age)) %>%
    mutate(age = ifelse(age == "75-79" | age == "80-84", "75-84", age)) %>%
    group_by(age) %>%
    summarise(weeklyDeaths = sum(deaths), .groups = "drop")

## join with table 2
table2 <- inner_join(table2, weekly, by = "age")
table2
```

```{info, title = "Note", collapsible = FALSE}
These numbers are slightly different to those in Figure \@ref(fig:table2). As far as I can tell this is because Spiegelhalter (2020) imports the male and female counts separately, and then sums them together, which (due to rounding error I think) does not match exactly to the overall averages reported in the `.xslx` file. These differences are only minor, and so we will proceed as normal, but feel free to combine the male and female counts if you prefer.
```

```{task}
Add a new column expressing the COVID-19 mortality risk as a % of the five-year average risk.
```

```{solution}

``{r}
## create new column of % of 5-year risk
table2 <- mutate(table2, perc5yearRisk = 100 * deaths / weeklyDeaths)
as.data.frame(table2)
``

```

```{task}
Calculate the equivalent extra days of normal risk associated with COVID-19 in each age-group. This can be calculated as the proportion of the 112 days of the study relating to the % of increased risk compared to the five-year averages. 
```

```{solution}

``{r}
## create new column of % of 5-year risk
table2 <- mutate(table2, addDaysRisk = 112 * deaths / weeklyDeaths)
as.data.frame(table2)
``

```

```{task}
Calculate the final row of Figure \@ref(fig:table2) and bind to the bottom of your data frame.
```

```{solution}

``{r}
table2 <- table2 %>%
    summarise(
        deaths = sum(deaths), 
        population = sum(population), 
        nonCovidDeaths = sum(nonCovidDeaths),
        weeklyDeaths = sum(weeklyDeaths),
        .groups = "drop"
    ) %>%
    mutate(PFR = 100000 * deaths / population) %>%
    mutate(percentage = 100 * deaths / population ) %>%
    mutate(PFR1 = population / deaths) %>%
    mutate(perc5yearRisk = 100 * deaths / weeklyDeaths) %>%
    mutate(addDaysRisk = 112 * deaths / weeklyDeaths) %>%
    mutate(age = "All ages") %>%
    rbind(table2) %>%
    arrange(age)
as.data.frame(table2)
``

```

Once you have the final data frame you can clean-up, re-order and present as in Table \@ref(tab:table2new).

```{r, table2new, echo = FALSE, results = "asis", message = FALSE, warning = FALSE}
library(kableExtra)
knitr::kable(
    select(table2, age, deaths, population, PFR, percentage, PFR1, nonCovidDeaths, weeklyDeaths, perc5yearRisk, addDaysRisk) %>%
    mutate(age = gsub("5-14", "05-14", age)) %>%
    arrange(age) %>%
    mutate(age = gsub("05-14", "5-14", age)) %>%
    mutate(age = gsub("-", "--", age)) %>%
    mutate(population = format(population, big.mark = ",", scientific = FALSE)) %>%
    mutate(deaths = format(deaths, big.mark = ",", scientific = FALSE)) %>%
    mutate(PFR = ifelse(PFR > 100, format(round(PFR), scientific = FALSE), format(round(PFR, digits = 1), scientific = FALSE, drop0trailing = TRUE))) %>%
    mutate(percentage = ifelse(percentage < 0.01, format(round(percentage), scientific = FALSE), format(signif(percentage, digits = 2), drop0trailing = TRUE, scientific = FALSE))) %>%
    mutate(PFR1 = paste0("1 in ", format(round(PFR1), big.mark = ",", scientific = FALSE))) %>%
    mutate(nonCovidDeaths = format(nonCovidDeaths, big.mark = ",", scientific = FALSE)) %>%
    mutate(weeklyDeaths = format(weeklyDeaths, big.mark = ",", scientific = FALSE)) %>%
    mutate(perc5yearRisk = format(round(perc5yearRisk))) %>%
    mutate(addDaysRisk = format(round(addDaysRisk))), 
    col.names = c("Age (years)", "No. of COVID-19 deaths", "Population", "COVID-19 rate / 100,000", "COVID-19 rate (%)", "COVID-19 rate (1 in ...)", "No. of non-COVID-19 deaths", "5 year average", "COVID-19 as % of 5 year average", "Equivalent days of normal risk"),
    align = "c", caption = "Mortality rates expressed in different ways") %>%
    column_spec(1:10, width = c(rep("1.2cm", 2), "1.8cm", rep("1.2cm", 6), "1.5cm")) %>%
    kable_styling(bootstrap_options = c("striped", "hover")) %>%
    row_spec(0, bold = TRUE) %>%
    row_spec(12, bold = TRUE)
```
